{"cells": [{"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "view-in-github"}, "source": "<a href=\"https://colab.research.google.com/github/nlp-course/materials/blob/tmp_psets/distrib/project4/project4_semantics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "qyLRFIJ0pWug"}, "source": "# Project 4: Semantic Parsing for Question Answering\n\nSemantic parsing is an important task in Natural Language Processing (NLP), where the goal is to convert natural language to its logical form, such as SQL. In the last project, you have built a parsing system to extract parse trees from the questions in the ATIS dataset. However, that only solves an intermediary task, not any end-user task.\n\nIn this project, you will go one step further to build a semantic parsing system to convert the questions to SQL queries, such that by consulting a database you will be able to answer those questions. You will implement both a rule-based approach and an end-to-end sequence-to-sequence (seq2seq) approach. Both algorithms come with their pros and cons, and by the end of this homework you should have a basic understanding of the characteristics of the traditional computational lingustic approach and the recent neural approach. \n\n## Goals\n\n1. Build a semantic parsing algorithm to convert text to SQL queries based on the syntactic parse trees from the last project.\n2. Build an end-to-end seq2seq system to convert text to SQL.\n3. Discuss the pros and cons of the rule-based system and the end-to-end system.\n\nThis will be a very challenging homework, so we recommend you to start early."}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "IZC1IGmoujpw"}, "source": "## Setup"}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "ebLelc9O0v4b"}, "outputs": [], "source": "!pip install -q dateparser\n!pip install -q nltk\n!pip install -q cryptography\n!pip install -qU torchtext\n!pip install -q mysql-connector"}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "U1jEUUYXpU0V"}, "outputs": [], "source": "import math\nimport copy\nimport requests\nimport datetime\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn.utils.rnn import pack_padded_sequence as pack\nimport torchtext as tt\n\nfrom tqdm import tqdm\n\nimport dateparser\n\nimport nltk\nfrom nltk.tree import Tree\nfrom nltk import treetransforms\n\nfrom cryptography.fernet import Fernet\n\nimport mysql.connector\nfrom mysql.connector import errorcode\n\n# Set random seeds\nseed = 1234\ntorch.manual_seed(seed)\n\n# GPU check, make sure to set runtime type to \"GPU\" where available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint (device)"}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "1aPr0imd09E2"}, "outputs": [], "source": "# Tree utils\n!wget -nv -N -P scripts https://raw.githubusercontent.com/nlp-course/data/master/scripts/trees/tree_utils.py\n!wget -nv -N -P scripts https://raw.githubusercontent.com/nlp-course/data/master/scripts/trees/tree_utils_private\n\n# Add parse_tree function from the solutions to the last segment\nkey = '5_pggebiNGJfgNYJOlQiDRGfi1PCZeRuo6vBYDKtza8='\nfernet = Fernet(key)\nwith open('scripts/tree_utils_private', 'rb') as fin:\n  with open('scripts/tree_utils.py', 'ab') as fout:\n    encrypted_data = fin.read()\n    fout.write('\\n'.encode())\n    fout.write(fernet.decrypt(encrypted_data))\n\nfrom scripts.tree_utils import parse_tree"}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "zBALH7ZHLjhh"}, "source": "### Load data\n\nIn this segment, we only consider `flight_id`-type questions."}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "AIVb--YGLVKd"}, "outputs": [], "source": "!wget -nv -N -P data https://raw.githubusercontent.com/nlp-course/data/master/ATIS/test_flightid.nl\n!wget -nv -N -P data https://raw.githubusercontent.com/nlp-course/data/master/ATIS/test_flightid.sql\n\n!wget -nv -N -P data https://raw.githubusercontent.com/nlp-course/data/master/ATIS/dev_flightid.nl\n!wget -nv -N -P data https://raw.githubusercontent.com/nlp-course/data/master/ATIS/dev_flightid.sql\n  \n!wget -nv -N -P data https://raw.githubusercontent.com/nlp-course/data/master/ATIS/train_flightid.nl\n!wget -nv -N -P data https://raw.githubusercontent.com/nlp-course/data/master/ATIS/train_flightid.sql"}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "UW7A_icx3zjr"}, "source": "Let's take a look at the data: the questions are in `.nl` files, and the SQL queries are in `.sql` files. The goal of this project is to convert a question to its corresponding SQL."}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "Ux_vIRC337FG"}, "outputs": [], "source": "!head -1 data/dev_flightid.nl\n!head -1 data/dev_flightid.sql"}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "32tFSXqiLq2h"}, "source": "### Data preprocessing"}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "GxjjnghgCJ_b"}, "source": "We use `torchtext` to process data. We use two Fields: `TEXT` for the questions, and `SQL` for the SQL queries."}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "ODU_4JYO8d9q"}, "outputs": [], "source": "def reverse(tokens):\n  \"\"\"Reverse a list\"\"\"\n  return list(reversed(tokens))\n\nTEXT = tt.data.Field(lower=True, # lowercased\n                     sequential=True, # sequential data\n                     include_lengths=True, # include lengths\n                     batch_first=False, # batches will be max_len X batch_size\n                     tokenize=lambda x: x.split(), # use split to tokenize\n                     preprocessing=reverse) \nSQL = tt.data.Field(sequential=True,\n                    include_lengths=False,\n                    batch_first=False,\n                    tokenize=lambda x: x.split(),\n                    init_token=\"<bos>\", # prepend <bos>\n                    eos_token=\"<eos>\")  # append <eos>\nfields = [('text_reversed', TEXT), ('sql', SQL)]"}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "PRXJ17mU99V0"}, "source": "Note that we reversed the tokens in question by passing in `preprocessing=reverse`. We did that because in seq2seq (w/o attention) this trick improves performance. You can refer to Section 3.3 in [the seminal seq2seq paper](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43155.pdf) for more details. Another difference is that we use `batch_first=False`, such that the returned batched tensors would be of size `max_length X batch_size`, which facilitates seq2seq implementation.\n\nNow, we load data using `torchtext`. We use `TranslationDataset` class here because our task is essentially a translation task: \"translating\" questions into the corresponding SQL queries. Therefore, we also refer to the questions as the source side, the SQL queries as the target side."}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "pIb_oHI33ga-"}, "outputs": [], "source": "# Make splits for data\ntrain_data, val_data, test_data = tt.datasets.TranslationDataset.splits(\n    ('_flightid.nl', '_flightid.sql'), fields, path='./data/',\n    train='train', validation='dev', test='test')\n\nMIN_FREQ = 3\nTEXT.build_vocab(train_data.text_reversed, min_freq=MIN_FREQ)\nSQL.build_vocab(train_data.sql, min_freq=MIN_FREQ)\n\nprint (f\"Size of English vocab: {len(TEXT.vocab)}\")\nprint (f\"Most comman English words: {TEXT.vocab.freqs.most_common(10)}\")\n\nprint (f\"Size of SQL vocab: {len(SQL.vocab)}\")\nprint (f\"Most comman SQL words: {SQL.vocab.freqs.most_common(10)}\")\n\nprint (f\"Start of sequence: {SQL.vocab.stoi[SQL.init_token]}\") # word id for bos\nprint (f\"End of sequence: {SQL.vocab.stoi[SQL.eos_token]}\")   # word id for eos"}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "y89Bvq7WJbc8"}, "source": "Next, we batch our data to facilitate processing on GPU. Batching is a bit tricky because source/target will be of different lengths. Fortunately, `torchtext` allows us to pass in a `sort_key` function. This will minimize the amount of padding on the source side, but since there is still some padding, we need to handle them with [`pack`](https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_padded_sequence.html#torch.nn.utils.rnn.pack_padded_sequence) later on in the seq2seq part. "}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "lnoY1oIj37bC"}, "outputs": [], "source": "BATCH_SIZE = 32 # batch size for training/validation\nTEST_BATCH_SIZE = 1 # batch size for test, we use 1 to make implementation easier\ntrain_iter, val_iter = tt.data.BucketIterator.splits((train_data, val_data), batch_size=BATCH_SIZE, device=device,\n                                                  repeat=False, sort_key=lambda x: len(x.text_reversed), sort_within_batch=True)\ntest_iter = tt.data.BucketIterator(test_data, batch_size=1, device=device,\n                                                  repeat=False, sort=False, train=False)"}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "kVzpFHVRKM1k"}, "source": "Let's look at a single batch from one of these iterators."}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "SeEpkHdiKVYV"}, "outputs": [], "source": "batch = next(iter(val_iter))\ntext, text_lengths = batch.text_reversed\nprint (f\"Size of text batch: {text.size()}\")\nprint (f\"Third sentence in batch: {text[:, 2]}\")\nprint (f\"Length of the third sentence in batch: {text_lengths[2]}\")\nprint (f\"Converted back to string: {' '.join([TEXT.vocab.itos[i] for i in text[:, 2]])}\")\n\nsql = batch.sql\nprint (f\"Size of sql batch: {sql.size()}\")\nprint (f\"Third label in batch: {sql[:, 2]}\")\nprint (f\"Converted back to string: {' '.join([SQL.vocab.itos[i] for i in sql[:, 2]])}\")"}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "LZe96xm-tx2-"}, "source": "Note that the question is reversed, and that the size of the batch is `max_length X batch_size`. Alternatively, we can directly iterate over the raw examples in train_data, val_data and test_data."}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "V6yIqRmwt2FA"}, "outputs": [], "source": "for example in val_iter.dataset: # val_iter.dataset is just val_data\n  text_reversed = example.text_reversed\n  text = ' '.join(reversed(text_reversed)) # detokenized question\n  sql = ' '.join(example.sql) # detokenized sql\n  print (f\"Question: {text}\")\n  print (f\"SQL: {sql}\")\n  break"}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "Vp_CdmJC5ZY2"}, "source": "\n### Remote ATIS Database\n\nThe output of our systems are SQL queries, but to get the actual answer, we need to execute those queries on a database. We have set up a remote MySQL database, and we will connect to it using mysql-connector later.\n"}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "0Mri4_xjCecY"}, "source": "## Rule-based Semantic Parsing\n\nFirst, we will implement a rule-based semantic parser using the parse trees from our last project."}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "3Vw9KC-T40aP"}, "source": "### CKY Parsing\n\nWe use our parse trees from the previous segment. We provide a function `parse_tree` which returns the parse tree as an `nltk.Tree` object. `parse_tree` is able to parse about 50% of ATIS questions, and it returns `None` if a question is not parsable. For higher coverage, feel free to use your own implementation."}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "93iiOXdkWv5c"}, "outputs": [], "source": "question = 'flights to boston'\ntree = parse_tree(question)\ntree.pretty_print()"}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "r9ImsH7kYGC2"}, "source": "### Semantic Parsing: The Basics"}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "-0MhfJ8jYX4s"}, "source": "The high-level idea of rule-based semantic parsing is to associate each grammar rule with a semantic rule. Given a sentence, we first construct its parse tree, then compose semantic rules bottom-up, until eventually we arrive at the root node with a finished SQL statement. \n\nWe use the above parse tree as an example. \n\n1. First, let the rule\n\n   **FLIGHT -> flights**\n\n   be accompanied by the semantic rule:\n\n   **SELECT DISTINCT flight.flight_id FROM flight**.\n\n\n2. To handle origin/destination constraint 'boston', we associate\n\n   **Place -> boston**\n\n   with\n\n   **(SELECT airport_service.airport_code FROM airport_service WHERE airport_service.city_code IN (SELECT city.city_code FROM city WHERE city.city_name = 'boston'))**.\n\n   Note that we look up the airport code instead of directly using city code, because the flight table which we later use expects the airport code.\n\n3. To distinguish destination from origin, we need to add a rule for: \n\n   **PPLACE -> to**. \n\n   We use lambda calculus here, since the SQL statement it produces is dependent on its siblings ('to boston' is different from 'to dallas'):\n\n   **$\\lambda$ x. \"(flight.to_airport IN (\" + x + \"))\"**.\n\n\n4. Now we need to merge *PPLACE* and *PLACE* at node *PP*:\n\n   **PP -> PPLACE PLACE**. \n\n   We simply use:\n\n   **left_child(right_child)**, \n\n   which denotes evaluating the left child to get a function, then applying that function with the right child as the input. In this case, this would evaluate to:\n\n   *(flight.to_airport IN (SELECT airport_service.airport_code FROM airport_service WHERE airport_service.city_code IN (SELECT city.city_code FROM city WHERE city.city_name = 'boston')))*\n\n\n5. For the rule\n\n   **PPS -> PP**,\n\n   we simply copy the evaluation result of the child:\n\n   **child**.\n\n6. Finally, the last piece to complete the puzzle is at the root node:\n\n   **S -> FLIGHT PPS**,\n\n   for which we only need to join the evaluation results of its left child and right child with a 'WHERE':\n\n   **left_child WHERE right_child**.\n\nPutting all these together, the final SQL statement we get (at root 'S') is:\n\n*SELECT DISTINCT flight.flight_id FROM flight WHERE (flight.to_airport IN (SELECT airport_service.airport_code FROM airport_service WHERE airport_service.city_code IN (SELECT city.city_code FROM city WHERE city.city_name = 'boston')))*,\n\nwhich should return the answer to the original question when used to query a MySQL database containing relevant flight information."}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "qF12SmJbDsYb"}, "source": "### Goal 1: Construct SQL queries from a parse tree and evaluate the results"}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "5iqruasFCaws"}, "source": "Implement a rule-based semantic parsing system to successfully answer **at least 25%** of flight_id type questions in the test set."}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "H8ciJheFAvml"}, "source": "#### Starter Code<!--TODO-->\n\nWe provide starter code for some functions that you will implement. \n\n\n*HINT: You may find it useful to use `WHERE TRUE AND (condition)` instead of `WHERE (condition)` in your queries. This way, if you want to add more conditions you can write it as such: `WHERE TRUE AND (condition1) AND (condition2)...`*"}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "NE0QpqZmxfWx"}, "source": "First, we provide a lexicon from our grammar.<!--TODO-->"}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "iYVEu32GxfW0"}, "outputs": [], "source": "#TODO\n# Lexicon\nlexicon = {\n  'ADJ': {\n    \"days\": set(\n      [\n        \"monday's\",\n        \"tuesday's\",\n        \"wednesday's\",\n        \"thursday's\",\n        \"friday's\",\n        \"saturday's\",\n        \"sunday's\",\n      ]\n    ),\n    \"availability\": set([\"available\", \"possible\"]),\n    \"seat_types\": set([\"first class\", \"economy\", \"thrift economy\"]),\n    \"price\": set([\"cheapest\", \"lowest cost\", \"least expensive\", \"most expensive\"]),\n    \"time\": set([\"weekday\", \"daily\", \"last\", \"first\"]),\n    \"attributes\": set([\"dinner\", \"transcontinental\"]),\n  },\n  'PDAY': {\n    \"arrive_on\": set(\n      [\n        \"returning on\",\n        \"arriving\",\n        \"arriving on\",\n        \"that arrive on\",\n        \"which arrive on\",\n      ]\n    ),\n    \"depart_on\": set(\n      [\n        \"on\",\n        \"of\",\n        \"for\",\n        \"next\",\n        \"the next\",\n        \"in the next\",\n        \"of next\",\n        \"leaving\",\n        \"which leave\",\n        \"leaving on\",\n      ]\n    ),\n  },\n  'PPLACE': {\n    \"dest\": set(\n      [\n        \"to\",\n        \"that arrive at\",\n        \"that arrives in\",\n        \"coming back to\",\n        \"that go to\",\n        \"and then to\",\n        \"arriving in\",\n        \"and arriving in\",\n        \"and arrive in\",\n        \"to arrive in\",\n        \"arrive in\",\n        \"going to\",\n        \"into\",\n        \"for\",\n        \"with the destination city of\",\n        \"arriving\",\n        \"goes to\",\n        \"flying into\",\n        \"goes on to\",\n        \"reaching\",\n        \"in\",\n        \"and then\",\n        \"arriving to\",\n      ]\n    ),\n    \"source\": set(\n      [\n        \"from\",\n        \"leaving\",\n        \"return from\",\n        \"leaving from\",\n        \"departing from\",\n        \"are departing from\",\n        \"departing\",\n        \"go from\",\n        \"going from\",\n        \"back from\",\n        \"that goes from\",\n        \"that departs\",\n        \"which leaves from\",\n        \"which leave\",\n        \"that leave\",\n        \"originating in\",\n        \"leave\",\n        \"out of\",\n        \"leaves from\",\n        \"to get from\"\n      ]\n    ),\n    \"through\": set(\n      [\n        \"via\",\n        \"with a stopover in\",\n        \"with a layover in\",\n        \"with a stopover at\",\n        \"and a stopover in\",\n        \"stop in\",\n        \"stopping in\",\n        \"make a stop in\",\n        \"with a stop in\",\n        \"with one stop in\",\n        \"go through\",\n        \"which go through\",\n        \"makes a stopover in\",\n        \"that stops in\",\n        \"that stops over in\",\n        \"by way of\",\n        \"connecting through\",\n        \"that will stop in\",\n        \"which connects in\",\n      ]\n    ),\n  },\n  'PTIME': {\n    \"arrive_by\": set(\n      [\n        \"that arrive before\",\n        \"that arrives before\",\n        \"arriving before\",\n        \"arrival by\",\n        \"arrives\",\n        \"before\",\n        \"departing before\",\n        \"that leaves before\",\n        \"which arrive before\",\n        \"by\",\n      ]\n    ),\n    \"arrive_at\": set(\n      [\n        \"around\",\n        \"that return around\",\n        \"that gets in around\",\n        \"at\",\n        \"arriving around\",\n        \"arriving about\",\n      ]\n    ),\n    \"arrive_after\": set([\"that arrive soon after\", \"arriving after\"]),\n    \"depart_at\": set(\n      [\n        \"leaving at\",\n        \"leaving\",\n        \"which leave after\",\n        \"leaving after\",\n        \"after\",\n        \"departing after\",\n        \"that depart after\",\n        \"departing at\",\n        \"are departing at\",\n      ]\n    ),\n    \"depart_in\": set([\"in\", \"departing in\", \"on\", \"that leaves in\"]),\n  },\n  'TIME': {\n    \"morning\": set(\n      [\n        \"the morning\",\n        \"the early am\",\n        \"mornings\",\n        \"as early as possible\",\n        \"earliest possible time\",\n        \"as soon thereafter as possible\",\n      ]\n    ),\n    \"afternoon\": set(\n      [\"the afternoon\", \"the late afternoon\", \"the day\", \"afternoons\"]\n    ),\n    \"evening\": set([\"the evening\", \"evenings\"]),\n  },\n}"}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "KIpXuVinxfW3"}, "source": "In addition to the provided lexicon, we also provide some helper functions. You will need to implement `eval_S`, which returns the SQL query based on a parse tree.<!--TODO-->"}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "1WxNQbgOxfW4"}, "outputs": [], "source": "#TODO\ndef eval_S(tree):\n  \"\"\"\n  Construct the SQL query based on a parse tree.\n  Arguments:\n      tree: an nltk.Tree.\n  Returns:\n      a string of the corresponding SQL query\n  \"\"\"\n  #TODO: implement this method.\n  PREJ = None\n  DET = None\n  ADJS = None\n  FLIGHT = None\n  PPS = None\n\n  for child in tree:\n    if child.label() == \"PREJ\":\n      PREJ = child\n    elif child.label() == \"DET\":\n      DET = child\n    elif child.label() == \"ADJS\":\n      ADJS = child\n    elif child.label() == \"FLIGHT\":\n      FLIGHT = child\n    elif child.label() == \"PPS\":\n      PPS = child\n\n  ### Implement these Rules\n  # S -> (PREJ) (DET) ADJS FLIGHT PPS\n  # S -> (PREJ) (DET) ADJS FLIGHT\n  # S -> (PREJ) (DET) FLIGHT PPS\n  # S -> (PREJ) (DET) FLIGHT\n  ### YOUR CODE HERE\n  raise NotImplementedError\n\ndef eval_FLIGHT(tree):\n  ### Implement these Rules\n  # FLIGHT -> 'flights' | 'flight' | 'to' 'fly'\n  ### YOUR CODE HERE\n  raise NotImplementedError\n\ndef eval_PPS(tree):\n  ### Implement these Rules\n  # PPS -> PP\n  # PPS -> PP PPS\n  ### YOUR CODE HERE\n  raise NotImplementedError\n\ndef eval_PP(tree):\n  # List of the labels of the children (e.g. ['PPLACE', 'PLACE'])\n  child_labels = [child.label() for child in tree]\n  ### Implement these Rules\n  # PP -> PPLACE PLACE OR PLACE\n  # PP -> PPLACE EITHER PLACE OR PLACE\n  # PP -> PPLACE PLACE\n  # PP -> BETWEEN PLACE AND PLACE\n  ### YOUR CODE HERE\n  raise NotImplementedError\n\ndef eval_PPLACE(tree):\n  PPLACE_lexicon = lexicon['PPLACE']\n  # Join multiword phrases\n  val = ' '.join(tree).strip()\n  ### Implement these Rules\n  # PPLACE -> <departing>\n  # PPLACE -> <arriving>\n  # PPLACE -> <layover>\n  ### YOUR CODE HERE\n  raise NotImplementedError\n\ndef eval_PLACE(tree):\n  # Join multiword phrases\n  val = ' '.join(tree)\n  ### Implement these Rules\n  # PLACE -> <city_name>\n  ### YOUR CODE HERE\n  raise NotImplementedError"}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "zoConst9BQSg"}, "source": "#### Evaluation\n\nWith a rule-based semantic parsing system, we can generate SQL queries given questions, and then execute those queries on a MySQL database to answer the given questions. To evaluate the performance of the system, we compare the returned results against the results of executing the ground truth queries. Note that we do not directly compare the predicted SQL queries to the gold SQL queries due to there being multiple ways of writing semantically equivalent queries."}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "3T3b43eHBTts"}, "source": "We provide a function `evaluate_accuracy` to compare the results from our generated SQL to the ground truth SQL."}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "zMGUCce9BXEd"}, "outputs": [], "source": "def evaluate_accuracy(predictions, sqls, questions=None):\n  \"\"\"\n  Evaluate accuracy by executing predictions on a remote MySQL database\n  and comparing returned results.\n  Arguments:\n      predictions: a list of predicted sqls or a single predicted sql.\n      sqls: a list of gold sql statements or a single gold sql.\n      questions: a list of questions or a single question. Optional.\n  Returns: accuracy.\n  \"\"\"\n  # Initial check for type of input\n  sqls = [sqls] if not isinstance(sqls, (list)) else sqls\n  predictions = [predictions] if not isinstance(predictions, (list)) else predictions\n  if questions is not None:\n    questions = [questions] if not isinstance(questions, (list)) else questions\n  else:\n    questions = ['N/A',] * len(sqls)\n  \n  # Connect to remote database\n  try:\n    conn = mysql.connector.connect(host='54.202.209.190', user='CS187', password='007')\n  except mysql.connector.Error as err:\n    if err.errno == errorcode.ER_ACCESS_DENIED_ERROR:\n      print(\"Something is wrong with your user name or password\")\n    else:\n      print(err)\n\n  c = conn.cursor()\n  c.execute('USE atis;')\n\n  # Evaluate each query and compare results\n  correct = 0\n  total = len(sqls)\n  for gold_sql, predicted_sql, question in zip(sqls, predictions, questions):\n    is_correct = True\n    if len(predicted_sql) == 0:\n      is_correct = False\n    else:\n      # Execute predicted sql\n      try:\n        c.execute(predicted_sql)\n        predicted_ret = c.fetchall()\n      except Exception as e:\n        predicted_ret = 'Syntax Error!'\n      # Execute gold sql\n      try:\n        c.execute(gold_sql)\n        gold_ret = c.fetchall()\n      except Exception as e:\n        gold_ret = 'Syntax Error!'\n      \n      if gold_ret == predicted_ret:\n        correct += 1\n      else:\n        is_correct = False\n    if not is_correct:\n      print (f\"\\nINCORRECT!\")\n      print (f\"Question: {question}\")\n      print (f\"Gold SQL: {gold_sql}\")\n      if len(predicted_sql) > 0:\n        print (f\"Gold Result: {gold_ret}\")\n      print (f\"Predicted SQL: {predicted_sql}\")\n      if len(predicted_sql) > 0:\n        print (f\"Predicted Result: {predicted_ret}\")\n  \n  conn.commit()\n  c.close()\n  conn.close()\n  return correct/total"}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "IPR4zSqzM58Z"}, "source": "To make development faster, we recommend starting with a few examples before running the full evaluation script."}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "JZNW0pWxBiyj"}, "outputs": [], "source": "# Example 1\nquestion = 'flights from phoenix to milwaukee'\ngold_sql = \"SELECT DISTINCT flight_1.flight_id FROM flight flight_1 , airport_service airport_service_1 , city city_1 , airport_service airport_service_2 , city city_2 WHERE flight_1.from_airport = airport_service_1.airport_code AND airport_service_1.city_code = city_1.city_code AND city_1.city_name = 'PHOENIX' AND flight_1.to_airport = airport_service_2.airport_code AND airport_service_2.city_code = city_2.city_code AND city_2.city_name = 'MILWAUKEE'\"\ntree = parse_tree(question)\ntree.pretty_print()\n\npredicted_sql = eval_S(tree)\nprint (f\"Accuracy: {evaluate_accuracy(predicted_sql, gold_sql, question)}\")"}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "_ER7QlkPK4pg"}, "outputs": [], "source": "# Example 2\nquestion = 'i would like a flight between boston and dallas'\ngold_sql = \"SELECT DISTINCT flight.flight_id FROM flight WHERE TRUE AND (flight.from_airport IN (SELECT airport_service.airport_code FROM airport_service WHERE airport_service.city_code IN (SELECT city.city_code FROM city WHERE city.city_name = 'BOSTON'))) AND (flight.to_airport IN (SELECT airport_service.airport_code FROM airport_service WHERE airport_service.city_code IN (SELECT city.city_code FROM city WHERE city.city_name = 'DALLAS')))\"\ntree = parse_tree(question)\ntree.pretty_print()\n\npredicted_sql = eval_S(tree)\nprint (f\"Accuracy: {evaluate_accuracy(predicted_sql, gold_sql, question)}\")"}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "AJQ58JuHK6_S"}, "outputs": [], "source": "# Example 3\nquestion = 'what flights are departing from houston or austin leaving at 7am sunday'\ngold_sql = \"SELECT DISTINCT flight.flight_id FROM flight WHERE TRUE AND TRUE AND ((flight.from_airport IN (SELECT airport_service.airport_code FROM airport_service WHERE airport_service.city_code IN (SELECT city.city_code FROM city WHERE city.city_name = 'HOUSTON'))) OR (flight.from_airport IN (SELECT airport_service.airport_code FROM airport_service WHERE airport_service.city_code IN (SELECT city.city_code FROM city WHERE city.city_name = 'AUSTIN')))) AND (flight.departure_time >= 630 AND flight.departure_time <= 730) AND (flight.flight_days IN (SELECT days.days_code FROM days WHERE days.day_name = 'sunday'))\"\ntree = parse_tree(question)\ntree.pretty_print()\n\npredicted_sql = eval_S(tree)\nprint (f\"Accuracy: {evaluate_accuracy(predicted_sql, gold_sql, question)}\")"}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "8BW7LSCcK84G"}, "outputs": [], "source": "# Example 4\nquestion = 'can i have a flight from san francisco that stops in dallas going to new york arriving before 6pm'\ngold_sql = \"SELECT DISTINCT flight.flight_id FROM flight WHERE TRUE AND (flight.from_airport IN (SELECT airport_service.airport_code FROM airport_service WHERE airport_service.city_code IN (SELECT city.city_code FROM city WHERE city.city_name = 'SAN FRANCISCO'))) AND (flight_stop.stop_airport IN (SELECT airport_service.airport_code FROM airport_service WHERE airport_service.city_code IN (SELECT city.city_code FROM city WHERE city.city_name = 'DALLAS'))) AND (flight.to_airport IN (SELECT airport_service.airport_code FROM airport_service WHERE airport_service.city_code IN (SELECT city.city_code FROM city WHERE city.city_name = 'NEW YORK'))) AND (flight.arrival_time <= 1800)\"\ntree = parse_tree(question)\ntree.pretty_print()\n\npredicted_sql = eval_S(tree)\nprint (f\"Accuracy: {evaluate_accuracy(predicted_sql, gold_sql, question)}\")"}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "xA3uatiaBX_f"}, "source": "Below is the full evaluation code. Note that you are required to get correct results on **at least 25%** of flight_id type questions from the test set."}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "HlO7riRGM3BT"}, "outputs": [], "source": "questions = []\npredictions = []\ngold_sqls = []\n\nfor example in test_iter.dataset:\n  # Input and output\n  text_reversed = example.text_reversed\n  question = ' '.join(reversed(text_reversed)) # detokenized question\n  gold_sql = ' '.join(example.sql) # detokenized sql\n  questions.append(question)\n  gold_sqls.append(gold_sql)\n  # Get parse tree\n  tree = parse_tree(question)\n  if tree is None:\n    predictions.append('')\n    continue\n  # Predict\n  try:\n    predicted_sql = eval_S(tree)\n  except Exception as e:\n    predictions.append('')\n    continue\n  predictions.append(predicted_sql)\n\nevaluate_accuracy(predictions, gold_sqls, questions)"}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "j00wMxHP3MnB"}, "source": "## End-to-End Seq2Seq Model"}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "hE17C1s0QhSq"}, "source": "Nowadays neural networks dominate the field of NLP research. In this part, we investigate if it is possible to use an end-to-end system to directly learn the mapping from the natural language questions to the SQL queries."}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "dGvpHlNnN3ym"}, "source": "### Goal 2: Implement a seq2seq model"}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "4TPBjDalLzXg"}, "source": "#### Model, Optimization and Decoding\n\nFor the sequence-to-sequence model, you need to implement the class `EncoderDecoder`. We have provided starter code for performing optimization, but there are at least five methods that you need to implement:\n\n1. `__init__`: an initializer where you can create network modules.\n\n2. `forward`: given question word ids of size `batch_size X max_length`, question lengths of size `batch_size` and SQL word ids `batch_size X max_length_sql`, returns logits `batch_size X max_length_sql`. Note that here the batch size can be greater than 1.\n\n3. `compute_loss`: computes loss by comparing output returned by forward to ground_truth which stores the true SQL word ids.\n\n4. `evaluate_ppl`: evaluate the current model's perplexity on a given dataset iterator. [Perplexity](https://en.wikipedia.org/wiki/Perplexity) is defined as $\\exp(-\\frac{\\text{total log likelihood})}{\\text{total number of words}})$, which can be roughly understood as how many random guesses the model needs to make to get a word correct.\n\n5. `predict`: Generates the target sequence (SQL) given the source sequence (question). Note that here you can assume the batch size to be always 1 for simplicity. Besides, you can use greedy decoding here, i.e., predicting the word with the highest probability at any time step, although in practice researchers use more complicated decoding methods such as beam search. \n\nThis implementation is essentially building an entire neural seq2seq system, so expect it to be very challenging. The code you write here can also be used for other seq2seq tasks such as machine translation and document summarization.\n\n*Hint: to handle source side paddings in `torch`, you can use somethine like `packed_src = pack(src, src_lengths)`. To handle target side paddings, you can use `ignore_index` when creating the loss function."}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "afAaAkJXMhO7"}, "outputs": [], "source": "#TODO\nclass EncoderDecoder(nn.Module):\n  def __init__(self, text, sql, embedding_size=512, hidden_size=512, layers=2,\n               dropout=0, bidirectional=False, share_decoder_input_output_embeds=False,\n               add_encoder_out_to_decoder_input=False):\n    \"\"\"\n    Initializer. Creates network modules and loss function. You do not need to\n    implement all features as long as you can achieve 30%+ accuracy.\n    Arguments:\n        text: text field\n        tag: sql field\n        embedding_size: word embedding size\n        hidden_size: hidden layer size\n        layers: number of layers\n        dropout: dropout\n        bidirectional: use bidirectional RNN cells\n        share_decoder_input_output_embeds: if True, set the weight matrix of the \n            final projection layer to be the same as decoder word embeddings.\n            This reduces the number of parameters and is found to improve performance.\n            See https://arxiv.org/pdf/1608.05859.pdf.\n        add_encoder_out_to_decoder_input: if True, add encoder output to every\n            step of decoder input. This trick keeps the decoder from forgetting\n            encoder outputs as it decodes.\n    \"\"\"\n    super(EncoderDecoder, self).__init__()\n    self.text = text\n    self.sql = sql\n    # Keep the vocabulary sizes available\n    self.V_src = len(text.vocab.itos)\n    self.V_tgt = len(sql.vocab.itos)\n    # Get special word ids or tokens\n    self.padding_id_src = text.vocab.stoi[text.pad_token]\n    self.padding_id_tgt = sql.vocab.stoi[sql.pad_token]\n    self.bos_id = sql.vocab.stoi[sql.init_token]\n    self.eos_id = sql.vocab.stoi[sql.eos_token]\n    self.eos_token = sql.eos_token\n\n    # Keep parameters available\n    self.embedding_size = embedding_size\n    self.hidden_size = hidden_size\n    self.layers = layers\n    self.dropout = dropout\n    self.share_decoder_input_output_embeds = share_decoder_input_output_embeds\n    self.bidirectional = bidirectional\n    self.add_encoder_out_to_decoder_input = add_encoder_out_to_decoder_input\n\n    #TODO: implement this method\n    # Create essential modules and loss function\n    \"your code here\"\n\n  def forward(self, src_words, src_lengths, tgt_words):\n    \"\"\"\n    Performs forward computation, returns logits.\n    Arguments:\n        src_words: question batch of size batch_size X max_length\n        src_lengths: question lengths of size batch_size\n        tgt_words: sql batch of size batch_size X max_length\n    \"\"\"\n    #TODO: implement this method\n    \"your code here\"\n    return logits\n\n  def compute_loss(self, logits, targets):\n    \"\"\"\n    Computes loss function with logits and target.\n    Arguments:\n        logits: tensor of size batch_size X max_length X V_tgt\n        targets: tensor of size batch_size X max_length\n    \"\"\"\n    #TODO: implement this method\n    \"your code here\"\n    return loss\n\n  def evaluate_ppl(self, iterator):\n    \"\"\"\n    Returns the model's perplexity on a given dataset `iterator`. We will\n    use it for model selection.\n    \"\"\"\n    # Switch to eval mode\n    self.eval()\n    #TODO: implement this method\n    \"your code here\"\n    return perplexity\n\n  def predict(self, src_words, src_lengths, max_tgt_length=200):\n    \"\"\"\n    Generates the target sequence (SQL) given the source sequence (question).\n    You only need to implemnt greedy decoding, i.e., at each decoding step,\n    find the word with the highest probability.\n    Note that for simplicity, we only use batch size 1.\n    Arguments:\n        src_words: a tensor of size (max_length, 1) storing question word ids.\n        src_lengths: a tensor of size (1) storing question length.\n        max_tgt_length: at most proceed this many steps of decoding\n    Returns: \n        a string of the generated SQL.\n    \"\"\"\n    # Switch to eval mode\n    self.eval()\n    #TODO: implement this method\n    \"your code here\"\n    decoded = 'SELECT DISTINCE * FROM flight'\n    return decoded\n    \n  def fit(self, train_iter, val_iter, epochs=50, learning_rate=3e-4):\n    \"\"\"Train the model.\"\"\"\n    # Switch the module to training mode\n    self.train()\n    # Use Adam to optimize the parameters\n    optim = torch.optim.Adam(self.parameters(), lr=learning_rate)\n    best_validation_ppl = float('inf')\n    best_model = None\n    # Run the optimization for multiple epochs\n    for epoch in range(epochs): \n      total_words = 0\n      total_loss = 0.0\n      for batch in tqdm(train_iter):\n        # Zero the parameter gradients\n        self.zero_grad()\n\n        # Input and target\n        text, text_lengths = batch.text_reversed # text: max_length_text, bsz\n        sql = batch.sql # max_length_sql, bsz\n        sql_in = sql[:-1] # Remove <eos> for decode input\n        sql_out = sql[1:] # Remove <bos> as target\n        batch_size = sql.size(1)\n        \n        # Run forward pass and compute loss along the way.\n        logits = self.forward(text, text_lengths, sql_in)\n        loss = self.compute_loss(logits, sql_out)\n\n        # Training stats\n        num_sql_words = sql_out.ne(self.padding_id_tgt).float().sum().item()\n        total_words += num_sql_words\n        total_loss += loss.item()\n        \n        # Perform backpropagation\n        loss.div(batch_size).backward()\n        optim.step()\n\n      # Evaluate and track improvements on the validation dataset\n      validation_ppl = self.evaluate_ppl(val_iter)\n      self.train()\n      if validation_ppl < best_validation_ppl:\n        best_validation_ppl = validation_ppl\n        self.best_model = copy.deepcopy(self.state_dict())\n      epoch_loss = total_loss / total_words\n      print (f'Epoch: {epoch} Training Perplexity: {math.exp(epoch_loss):.4f} '\n             f'Validation Perplexity: {validation_ppl:.4f}')"}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "JLuzTt-RFgoL"}, "source": "After implementing the `EncoderDecoder` class, you can use the below script to create the model and kick off training. You are free to tune the hyperparameters."}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "t4fGKij64rkQ"}, "outputs": [], "source": "EPOCHS = 10 # epochs, we highly recommend starting with a smaller number like 1\nLEARNING_RATE = 3e-4 # learning rate\n# Instantiate and train classifier\nmodel = EncoderDecoder(TEXT, SQL,\n  embedding_size = 1024,\n  hidden_size    = 1024,\n  dropout        = 0.1,\n  layers         = 3,\n  bidirectional  = True,\n  share_decoder_input_output_embeds = True,\n  add_encoder_out_to_decoder_input = True,\n).to(device)\n\nmodel.fit(train_iter, val_iter, epochs=EPOCHS, learning_rate=LEARNING_RATE)\nmodel.load_state_dict(model.best_model)\n\n# Evaluate model performance, the expected value shall be < 1.3\n# We use validation set because this particular test set has a different distribution\nprint (f'Validation perplexity: {model.evaluate_ppl(val_iter):.3f}')"}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "dKkyL41z9ggD"}, "source": "#### Evaluation"}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "kLyrRJPsqPEs"}, "source": "Now we are ready to run the full evaluation. For seq2seq, a proper implementation should reach at least 30% accuracy."}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "vesYcMfF8XYz"}, "outputs": [], "source": "questions = []\npredictions = []\ngold_sqls = []\n\nfor example in test_iter.dataset: # val_iter.dataset is just val_data\n  # Input and output\n  text_reversed_str = example.text_reversed\n  question = ' '.join(list(reversed(text_reversed_str))) # detokenized question\n  gold_sql = ' '.join(example.sql) # detokenized sql\n  questions.append(question)\n  gold_sqls.append(gold_sql)\n  # Predict\n  text, text_lengths = TEXT.process([text_reversed_str])\n  text = text.to(device)\n  text_lengths = text_lengths.to(device)\n  prediction = model.predict(text, text_lengths)\n  print (prediction)\n  predictions.append(prediction)\n  \nevaluate_accuracy(predictions, gold_sqls, questions)"}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "HV5Q1nuCReVv"}, "source": "## Discussion"}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "fwg23wdz1o8o"}, "source": "### Goal 3: Compare the pros and cons of rule-based and neural approaches.\n\nCompare the pros and cons of both approaches with relevant examples from your experiments above. Concerning the accuracy, which approach would you choose to be used in a product? Explain."}], "metadata": {"accelerator": "GPU", "colab": {"collapsed_sections": [], "include_colab_link": true, "name": "project4_semantics.ipynb", "provenance": [], "toc_visible": true}, "kernelspec": {"display_name": "Python 3", "name": "python3"}}, "nbformat": 4, "nbformat_minor": 0}
